base:
  model_type: text_recognition
  algorithm: MASTER
  save_dir: saved
  gpu_id: 0,1
  resume: False
  ckpt_file: checkpoint/model_best.pth

dataset:
  new_shape: [256, 32]
  train_load:
    train_img_dir: 'dataset/..'
    train_label_dir: 'dataset/..'
    batch_size: 16
    num_workers: 4
  test_load:
    test_img_dir: 'dataset/..'
    test_label_dir: 'dataset/..'
    batch_size: 16
    num_workers: 4
  preprocess:
    case_sensitive: False
    to_gray: False
    transform: Resize
    target_transform: None
  function: ultocr.loader.recognition.reg_loader, RegLoader

model_arch:
  gcb:
    in_channels: 32
    ratio: 0.0625
    headers: 8
    pooling_type: 'att'
    att_scale: True
    fusion_type: 'channel_concat'
  backbone:
    use_gcb: [False, True, True, True]
  common:
    with_encoder: False
    tgt_vocab: 36
    d_model: 512
    nhead: 8
  encoder:
    num_layer: 3
    dropout: 0.2
    ff_dim: 2048
    share_parameter: False
  decoder:
    num_layer: 3
    dropout: 0.2
    ff_dim: 2048
    share_parameter: False

functional:
  load_data: ultocr.loader.reg_loader,TextDataset
  conv_embedding_gc: ultocr.model.common.resnet,ConvEmbeddingGC
  embedding: ultocr.model.common.transformer,Embeddings
  multi_head_attention: ultocr.model.common.transformer,MultiHeadAttention
  feed_forward: ultocr.model.common.transformer,FeedForward
  position: ultocr.model.common.transformer,PositionEncoding
  generator: ultocr.model.recognition.master,Generator
  master: ultocr.model.recognition.master,MASTER

optimizer:
  type: 'Adam'
  functional: ultocr.model.optimizer,Adam
  lr: 0.0004

lr_scheduler:
  type: 'StepLR'
  step_size: 30
  gamma: 0.1

trainer:
  epochs: 100
  do_validation: True
  validation_epoch: 10
  log_step_interval: 1
  val_step_interval: 2000
  save_dir: 'saved'
  monitor: 'max_word_acc'
  distributed: True
  local_world_size: 4
  local_rank: -1
  global_rank: -1
  early_stop: -1


